databaseA [,3:ncol(databaseA) ]<-as.matrix( datA)
databaseA <- data.frame(databaseA)
colnames(databaseA)=c("Time","delta",paste("R", 1:K, sep = ""),"id")
return(list(surv_data=surv_data,XB=XB,databaseB=databaseB,
databaseA=databaseA,datB=datB,datA=datA,idBA=idBA) )
}
##################################### 1 block ###########################
generate_1block <- function(K,nA, nB, p,prevalence, beta,block){
blockA = rep(block, nA)
blockB = rep(block, nB)
# Survival data (Database B)
ft<- Generate_data(K,nA,nB,prevalence, min_prev = 0.01)
surv_data<-ft$surv_data
XB <- ft$XB #Only covariates
######
datA<-ft$datA  # matching variables
datB<-ft$datB
datA<- cbind(datA, block= blockA)
datB<- cbind(datB, block= blockB)
XB <- as.data.frame(cbind(XB, block = blockB))
return(list( surv_data = surv_data, datA = datA, XB = XB, datB = datB))
}
##################################### 1 block ###########################
generate_1block <- function(K,nA, nB, p,prevalence, beta,block){
blockA = rep(block, nA)
blockB = rep(block, nB)
# Survival data (Database B)
ft<- Generate_data(K,nA,nB,prevalence, min_prev = 0.01)
surv_data<-ft$surv_data
XB <- ft$XB #Only covariates
######
datA<-ft$datA  # matching variables
datB<-ft$datB
datA<- cbind(datA, block= blockA)
datB<- cbind(datB, block= blockB)
XB <- as.data.frame(cbind(XB, block = blockB))
return(list( surv_data = surv_data, datA = datA, XB = XB, datB = datB))
}
library(survival)
library(plyr)
library(dplyr)
library(rootSolve)
library(nleqslv)
library(mvtnorm)
library(glmnet)
library(matrixStats)
library(clue)
#Exponential data and exponential error
generate_data_exp_exp = function(nA, nB, K, lambdaK, error, lambdaE, round ){
if (round == FALSE){
XA = matrix(rexp(nA*K,rate = lambdaK),ncol = K)
#S= sample(1:nA,nB)
XA1 = XA[1:nB,]
XA2  = XA[-(1:nB),]
X = matrix(rbinom(nB*K, 1, error), ncol =K)
XB = (1-X)* XA1 + X*(XA1 + matrix(rexp(nB*K, rate = lambdaE),ncol =K))
datA = matrix(0,nrow = nA, ncol = K+1)
datB = matrix(0,nrow = nB, ncol = K+1)
datA[,1:K] = XA
datA[,K+1] = 1:nA #id
datB[,1:K] = XB
datB[,K+1] = 1:nB #id
}else if (round == TRUE){
XA = matrix(ceiling(rexp(nA*K,rate = lambdaK)),ncol = K)
#S= sample(1:nA,nB)
XA1 = XA[1:nB,]
XA2  = XA[-(1:nB),]
X = matrix(rbinom(nB*K, 1, error), ncol =K)
XB = (1-X)* XA1 + X*(XA1 + matrix(ceiling(rexp(nB*K, rate = lambdaE)), ncol =K))
datA = matrix(0,nrow = nA, ncol = K+1)
datB = matrix(0,nrow = nB, ncol = K+1)
datA[,1:K] = XA
datA[,K+1] = 1:nA #id
datB[,1:K] = XB
datB[,K+1] = 1:nB #id
}
#####
return(list(dataA=datA, dataB = datB))
}
generate <- generate_data_exp_exp(nA, nB, K, lambdaK, error, lambdaE, round )
nA=10
nB=20
K=7
#Exponential data and exponential error
generate_data_exp_exp = function(nA, nB, K, lambdaK, error, lambdaE, round ){
if (round == FALSE){
XA = matrix(rexp(nA*K,rate = lambdaK),ncol = K)
#S= sample(1:nA,nB)
XA1 = XA[1:nB,]
XA2  = XA[-(1:nB),]
X = matrix(rbinom(nB*K, 1, error), ncol =K)
XB = (1-X)* XA1 + X*(XA1 + matrix(rexp(nB*K, rate = lambdaE),ncol =K))
datA = matrix(0,nrow = nA, ncol = K+1)
datB = matrix(0,nrow = nB, ncol = K+1)
datA[,1:K] = XA
datA[,K+1] = 1:nA #id
datB[,1:K] = XB
datB[,K+1] = 1:nB #id
}else if (round == TRUE){
XA = matrix(ceiling(rexp(nA*K,rate = lambdaK)),ncol = K)
#S= sample(1:nA,nB)
XA1 = XA[1:nB,]
XA2  = XA[-(1:nB),]
X = matrix(rbinom(nB*K, 1, error), ncol =K)
XB = (1-X)* XA1 + X*(XA1 + matrix(ceiling(rexp(nB*K, rate = lambdaE)), ncol =K))
datA = matrix(0,nrow = nA, ncol = K+1)
datB = matrix(0,nrow = nB, ncol = K+1)
datA[,1:K] = XA
datA[,K+1] = 1:nA #id
datB[,1:K] = XB
datB[,K+1] = 1:nB #id
}
#####
return(list(dataA=datA, dataB = datB))
}
lambdaK=0,2
lambdaK=0,2
lambdaK=0.2
error=0.02
lambdaE = 0.01
round=TRUE
library(RecordLinkage)
#library(plyr)
#library(dplyr)
data("RLdata500")
data("RLdata10000")
s1 <- 1:100
s2 <- 1:100
datasetB <- rbind( RLdata10000[s2,],RLdata500[s1,])
datasetA <- RLdata500[s1,]
var_block= "fname_c1"
matching_variables = colnames(datasetA)
linkage_function<- function(datasetA,datasetB,var_block){
# pairs with blocking variable
p <- pair_blocking (datasetA, datasetB,var_block , FALSE)
#p <- print(p)
#  comparison matrix of pairs
p <- compare_pairs ( p, on= matching_variables,
comparators = list(fname_c2 = jaro_winkler(),
lname_c1 = jaro_winkler(), lname_c2  = jaro_winkler() ) )
#p <- print(p)
## classification
p0 = 1/length(datasetB)
model <- problink_em ( ~ fname_c1+fname_c2 +lname_c1 +lname_c2 +by +bm+bd , data=p,
mprobs0 = list(0.9),uprobs0 = list(0.02),p0 = p0 ,tol = 1e-05,
mprob_max = 0.999, uprob_min = 1e-04)
#print(model)
p_compar <- predict(model, p, type ="mpost", add = TRUE, binary = TRUE)
prob_match <- p_compar[,c(1:2,10)]
return(prob_match=prob_match)
}
prob_match = linkage_function (datasetA,datasetB,var_block)
var_block= "fname_c1"
matching_variables = colnames(datasetA)
linkage_function<- function(datasetA,datasetB,var_block){
# pairs with blocking variable
p <- pair_blocking (datasetA, datasetB,var_block , FALSE)
#p <- print(p)
#  comparison matrix of pairs
p <- compare_pairs ( p, on= matching_variables,
comparators = list(fname_c2 = jaro_winkler(),
lname_c1 = jaro_winkler(), lname_c2  = jaro_winkler() ) )
#p <- print(p)
## classification
p0 = 1/length(datasetB)
model <- problink_em ( ~ fname_c1+fname_c2 +lname_c1 +lname_c2 +by +bm+bd , data=p,
mprobs0 = list(0.9),uprobs0 = list(0.02),p0 = p0 ,tol = 1e-05,
mprob_max = 0.999, uprob_min = 1e-04)
#print(model)
p_compar <- predict(model, p, type ="mpost", add = TRUE, binary = TRUE)
prob_match <- p_compar[,c(1:2,10)]
return(prob_match=prob_match)
}
prob_match = linkage_function (datasetA,datasetB,var_block)
library(plyr)
data("RLdata500")
data("RLdata10000")
s1 <- 1:100
s2 <- 1:100
datasetB <- rbind( RLdata10000[s2,],RLdata500[s1,])
datasetA <- RLdata500[s1,]
var_block= "fname_c1"
matching_variables = colnames(datasetA)
linkage_function<- function(datasetA,datasetB,var_block){
# pairs with blocking variable
p <- pair_blocking (datasetA, datasetB,var_block , FALSE)
#p <- print(p)
#  comparison matrix of pairs
p <- compare_pairs ( p, on= matching_variables,
comparators = list(fname_c2 = jaro_winkler(),
lname_c1 = jaro_winkler(), lname_c2  = jaro_winkler() ) )
#p <- print(p)
## classification
p0 = 1/length(datasetB)
model <- problink_em ( ~ fname_c1+fname_c2 +lname_c1 +lname_c2 +by +bm+bd , data=p,
mprobs0 = list(0.9),uprobs0 = list(0.02),p0 = p0 ,tol = 1e-05,
mprob_max = 0.999, uprob_min = 1e-04)
#print(model)
p_compar <- predict(model, p, type ="mpost", add = TRUE, binary = TRUE)
prob_match <- p_compar[,c(1:2,10)]
return(prob_match=prob_match)
}
prob_match = linkage_function (datasetA,datasetB,var_block)
library(dplyr)
data("RLdata500")
data("RLdata10000")
s1 <- 1:100
s2 <- 1:100
datasetB <- rbind( RLdata10000[s2,],RLdata500[s1,])
datasetA <- RLdata500[s1,]
var_block= "fname_c1"
matching_variables = colnames(datasetA)
linkage_function<- function(datasetA,datasetB,var_block){
# pairs with blocking variable
p <- pair_blocking (datasetA, datasetB,var_block , FALSE)
#p <- print(p)
#  comparison matrix of pairs
p <- compare_pairs ( p, on= matching_variables,
comparators = list(fname_c2 = jaro_winkler(),
lname_c1 = jaro_winkler(), lname_c2  = jaro_winkler() ) )
#p <- print(p)
## classification
p0 = 1/length(datasetB)
model <- problink_em ( ~ fname_c1+fname_c2 +lname_c1 +lname_c2 +by +bm+bd , data=p,
mprobs0 = list(0.9),uprobs0 = list(0.02),p0 = p0 ,tol = 1e-05,
mprob_max = 0.999, uprob_min = 1e-04)
#print(model)
p_compar <- predict(model, p, type ="mpost", add = TRUE, binary = TRUE)
prob_match <- p_compar[,c(1:2,10)]
return(prob_match=prob_match)
}
prob_match = linkage_function (datasetA,datasetB,var_block)
# pairs with blocking variable
p <- pair_blocking (datasetA, datasetB,var_block , FALSE)
var_block
# pairs with blocking variable
p <- pair_blocking (datasetA, datasetB,var_block , FALSE)
library(RecordLinkage)
library(plyr)
library(dplyr)
data("RLdata500")
data("RLdata10000")
s1 <- 1:100
s2 <- 1:100
datasetB <- rbind( RLdata10000[s2,],RLdata500[s1,])
datasetA <- RLdata500[s1,]
var_block= "fname_c1"
matching_variables = colnames(datasetA)
linkage_function<- function(datasetA,datasetB,var_block){
# pairs with blocking variable
p <- pair_blocking (datasetA, datasetB,var_block , FALSE)
#p <- print(p)
#  comparison matrix of pairs
p <- compare_pairs ( p, on= matching_variables,
comparators = list(fname_c2 = jaro_winkler(),
lname_c1 = jaro_winkler(), lname_c2  = jaro_winkler() ) )
#p <- print(p)
## classification
p0 = 1/length(datasetB)
model <- problink_em ( ~ fname_c1+fname_c2 +lname_c1 +lname_c2 +by +bm+bd , data=p,
mprobs0 = list(0.9),uprobs0 = list(0.02),p0 = p0 ,tol = 1e-05,
mprob_max = 0.999, uprob_min = 1e-04)
#print(model)
p_compar <- predict(model, p, type ="mpost", add = TRUE, binary = TRUE)
prob_match <- p_compar[,c(1:2,10)]
return(prob_match=prob_match)
}
prob_match = linkage_function (datasetA,datasetB,var_block)
# pairs with blocking variable
p <- pair_blocking (datasetA, datasetB,var_block , FALSE)
library(RecordLinkage)
library(plyr)
library(dplyr)
data("RLdata500")
pairs=compare.dedup(RLdata500,identity=identity.RLdata500,
blockfld=list(c(5,6),c(6,7),c(5,7)))#prendre comme variable de blockline list
summary(pairs)
pairs1=compare.dedup(dataset1,identity=id1,
blockfld=c(1,5))#prendre comme variable de blockline list
#blocking
p <- pair_blocking (dataset1, dataset2,"fname_c1" , FALSE)
showClass("RLBigData")
showClass("RLBigDataDedup")
showClass("RLBigDataLinkage")
data("RLdata500")
data("RLdata10000")
data("RLdata500")
data("RLdata10000")
library(reclin2)
s1 <- 496:500
s2 <- sample(1:10000, 15)
dataset1 <- rbind( RLdata10000[s2,],RLdata500[s1,])
dataset1$id1 <- c(identity.RLdata10000[s2], identity.RLdata500[s1])
dataset2 <- RLdata500[476:500,]
dataset2$id2 <- identity.RLdata500[476:500]
attach(dataset1)
attach(dataset2)
#dataset1$id1 <- identity1
#enlever les doublures
pairs1=compare.dedup(dataset1,identity=id1,
blockfld=c(1,5))#prendre comme variable de blockline list
summary(pairs1)
#blocking
p <- pair_blocking (dataset1, dataset2,"fname_c1" , FALSE)
#blocking
p <- pair_blocking (dataset1, dataset2,"fname_c1" , FALSE)
pairs2
pairs1
library(survival)
library(rootSolve)
library(nleqslv)
setwd("C:/Users/fchezeut/Documents/GitHub/Cox-matched-data/FS-method")
source("7_scenarios.R")
source("1_FS.R")
source("1_data_generate.R")
source("2_risk_function.R")
source("3_naive_method.R")
source("4_method_w_sum1.R")
source("5_method_w_sum2.R")
source("6_method_EM.R")
View(datasetB)
coef_true_s = matrix(0,nrow = nsim, ncol = p)
coef_naive_s = matrix(0,nrow = nsim, ncol = p)
converge_naive = vector()
coef_w_sum1_s = matrix(0,nrow = nsim, ncol = p)
converge_w_sum1 = vector()
coef_w_sum2_s = matrix(0,nrow = nsim, ncol = p)
converge_w_sum2 = vector()
coef_estimate_s = matrix(0,nrow = nsim, ncol = p)
converge_estimate = vector()
prob_match = linkage_function (datasetA,datasetB,var_block,matching_variables)
data_block = function_block ( prob_match, datasetA, datasetB)
blockA =data_block$blockA
new_dataA= data_block$new_dataA
new_dataB = data_block$new_dataB
Q= Matrix_block (blockA,datasetA,datasetB,new_dataA,new_dataB,prob_match)
View(Q)
View(datasetA)
View(datasetB)
View(new_dataA)
View(datasetB)
View(new_dataB)
library(survival)
library(rootSolve)
library(nleqslv)
setwd("C:/Users/fchezeut/Documents/GitHub/Cox-matched-data/FS-method")
source("7_scenarios.R")
source("1_FS.R")
source("1_data_generate.R")
source("2_risk_function.R")
source("3_naive_method.R")
source("4_method_w_sum1.R")
source("5_method_w_sum2.R")
source("6_method_EM.R")
################### nsim monte carlos
estimates_survival<- function(nsim,nA,nB,p,beta,datasetA,datasetB,var_block,matching_variables){
coef_true_s = matrix(0,nrow = nsim, ncol = p)
coef_naive_s = matrix(0,nrow = nsim, ncol = p)
converge_naive = vector()
coef_w_sum1_s = matrix(0,nrow = nsim, ncol = p)
converge_w_sum1 = vector()
coef_w_sum2_s = matrix(0,nrow = nsim, ncol = p)
converge_w_sum2 = vector()
coef_estimate_s = matrix(0,nrow = nsim, ncol = p)
converge_estimate = vector()
prob_match = linkage_function (datasetA,datasetB,var_block,matching_variables)
data_block = function_block ( prob_match, datasetA, datasetB)
blockA =data_block$blockA
new_dataA= data_block$new_dataA
new_dataB = data_block$new_dataB
Q= Matrix_block (blockA,datasetA,datasetB,new_dataA,new_dataB,prob_match)
for (i in 1:nsim){
#data generation
mf = Generate_data(nA,nB,idBA,beta)
surv_data = mf$surv_data
XB = mf$XB
data_true=surv_data
Ts = data_true$Time
event = data_true$delta
naive_id = apply( Q,1, which.max)
Z = as.matrix(XB[naive_id,])
naive_data = cbind(Ts,event,Z)
naive_data= data.frame(naive_data)
# Matching_naive= new_dataB[naive_id,]
lambda0 =  rep(0.1,length(event))
lambda0 [which(event == 0)] = 0
beta0 = rep(0.1,p)
# times of event
# death_times= Ts[which(event==1)]
# Theoretical estimating equation for true and naive data
fit_true = coxph(Surv(Time,delta)~.,data = data_true)
coef_true_s[i,] = as.vector(fit_true$coefficients)
# naive method
fit_naive = coxph_equa_naive(Ts,event, Z, maxiter = 20)
coef_naive_s[i,] = fit_naive$coef
converge_naive[i] = fit_naive$converge
# method with weighted average
fit_w_sum1 = coxph_w_sum1(Ts,event,XB, Q,maxiter = 20)
coef_w_sum1_s[i,] = fit_w_sum1$coef
converge_w_sum1[i] = fit_w_sum1$converge
#method with the maximum of proba
fit_w_sum2 = coxph_w_sum2(Ts,event,XB, Q, maxiter = 20)
coef_w_sum2_s[i,] = fit_w_sum2$coef
converge_w_sum2[i] = fit_w_sum2$converge
# EM method
fit_estimate = Func_itteration(beta0,lambda0,Ts,event,XB,Q,tol= 1e-6,maxits = 500)
coef_estimate_s[i,] = fit_estimate$beta0
converge_estimate[i] = as.numeric(fit_estimate$converge)
}
return(list( coef_true_s1 = coef_true_s[,1], coef_true_s2 = coef_true_s[,2],coef_true_s3 = coef_true_s[,3],
coef_naive_s1 = coef_naive_s[,1], coef_naive_s2 = coef_naive_s[,2], coef_naive_s3 = coef_naive_s[,3], coef_w_sum1_s1 = coef_w_sum1_s[,1],
coef_w_sum1_s2 = coef_w_sum1_s[,2],coef_w_sum1_s3 = coef_w_sum1_s[,3], coef_w_sum2_s1 = coef_w_sum2_s[,1], coef_w_sum2_s2 = coef_w_sum2_s[,2],
coef_w_sum2_s3 = coef_w_sum2_s[,3], coef_estimate_s1 = coef_estimate_s[,1], coef_estimate_s2 = coef_estimate_s[,2],
coef_estimate_s3 = coef_estimate_s[,3],  converge_naive = converge_naive,
converge_w_sum1= converge_w_sum1,converge_w_sum2 = converge_w_sum2, converge_estimate = converge_estimate ))  }
######################################
setwd("C:/Users/fchezeut/Documents/GitHub/Cox-matched-data/FS-method")
results = estimates_survival(nsim,nA,nB,p,beta,datasetA,datasetB,var_block,matching_variables) #monte carlos
filename = paste0("C:/Users/fchezeut/Documents/GitHub/Cox-matched-data/FS-method/Results/","nsim=",nsim,
"_nA=",nA,".Rdata")
save(results,file = filename)
#data generation
mf = Generate_data(nA,nB,idBA,beta)
surv_data = mf$surv_data
XB = mf$XB
data_true=surv_data
Ts = data_true$Time
event = data_true$delta
naive_id = apply( Q,1, which.max)
Z = as.matrix(XB[naive_id,])
naive_data = cbind(Ts,event,Z)
naive_data= data.frame(naive_data)
# Matching_naive= new_dataB[naive_id,]
lambda0 =  rep(0.1,length(event))
lambda0 [which(event == 0)] = 0
beta0 = rep(0.1,p)
# times of event
View(surv_data)
######################## ####################
##############
### boxplots
setwd("C:/Users/fchezeut/Documents/GitHub/Cox-matched-data/FS-method")
source("7_scenarios.R")
library(ggplot2)
library(gridExtra)
library(xtable)
load(paste0("C:/Users/fchezeut/Documents/GitHub/Cox-matched-data/FS-method/Results/",
"nsim=",nsim,"_nA=",nA,".Rdata"))
results = results
function_plot <- function(nsim){
boxplot_beta0_true = cbind(rep(1,times=nsim),
rep(1, times=nsim),
results$coef_true_s1,
results$coef_true_s2,
results$coef_true_s3)
boxplot_beta0_naive = cbind(rep(2,times=nsim),
rep(2, times=nsim),
results$coef_naive_s1,
results$coef_naive_s2,
results$coef_naive_s3)
boxplot_beta0_w_sum1 = cbind(rep(3,times=nsim),
rep(3,times=nsim),
results$coef_w_sum1_s1,
results$coef_w_sum1_s2,
results$coef_w_sum1_s3)
boxplot_beta0_w_sum2 = cbind(rep(4,times=nsim),
rep(4,times=nsim),
results$coef_w_sum2_s1,
results$coef_w_sum2_s2,
results$coef_w_sum2_s3)
boxplot_beta0_estimate = cbind(rep(5,times=nsim),
rep(5,times=nsim),
results$coef_estimate_s1,
results$coef_estimate_s2,
results$coef_estimate_s3)
boxplot_beta0 = rbind(boxplot_beta0_true,boxplot_beta0_naive,boxplot_beta0_w_sum1,
boxplot_beta0_w_sum2,boxplot_beta0_estimate )
return(boxplot_beta0)
}
boxplot_beta0 = function_plot (nsim)
titlename = paste0("nB=",nB, ", ","nA=",nA)
colnames(boxplot_beta0) = c("Estimator","position","beta0.1","beta0.2","beta0.3")
boxplot_beta0 = data.frame(boxplot_beta0)
boxplot_beta0[,1] = factor(boxplot_beta0[,1],
levels = 1:5, labels = c("True"," Naive", "weighted average", "2-max weighted average", "EM"))
boxplot_beta0[,3] = as.numeric(boxplot_beta0[,3] )
boxplot_beta0[,4] = as.numeric(boxplot_beta0[,4] )
boxplot_beta0[,5] = as.numeric(boxplot_beta0[,5] )
attach(boxplot_beta0)
# Boxplots for beta0
beta0_1 = ggplot(boxplot_beta0,aes(x=position,y= beta0.1,fill=Estimator))+
geom_boxplot()+
xlab(position)+
ylab(quote(hat(beta)[1]))+
geom_hline(yintercept=beta[1],lty=1,col="orange")+
ggtitle(titlename)
beta0_1
beta0_2 = ggplot(boxplot_beta0,aes(x=position,y= beta0.2,fill=Estimator))+
geom_boxplot()+
xlab(position)+
ylab(quote(hat(beta)[2]))+
geom_hline(yintercept=beta[2],lty=1,col="orange")+
ggtitle(titlename)
beta0_2
beta0_3 = ggplot(boxplot_beta0,aes(x=position,y= beta0.3,fill=Estimator))+
geom_boxplot()+
xlab(position)+
ylab(quote(hat(beta)[3]))+
geom_hline(yintercept=beta[3],lty=1,col="orange")+
ggtitle(titlename)
beta0_3
View(prob_match)
