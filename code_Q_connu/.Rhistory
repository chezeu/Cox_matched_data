datB[,1:K] = sapply(prevalence, function(x){rbinom(nB, size = 1,prob = x)})
conditionB = (sum(colSums(datB[,1:K]/nB) >= min_prev) < K)
}
datB = data.frame(datB)
colnames(datB)=c(paste("R", 1:K, sep = ""),"id")
conditionA = TRUE
while (conditionA) {
# Second database A
idBA <- sample(1:nB,nA) #ident in A appearing in B
datA <- datB[idBA,]
# Make error for A
datA[,1:K]= apply(datA[,1:K], MARGIN = 2, FUN = makeError, error = error)
conditionA = (sum(colSums(datA[,1:K]) >= 1) < K)
}
databaseB <- matrix(0,nB,(p+K+1))
databaseB[,1:2] <- as.matrix(surv_data[,3:(p+2)])
databaseB [,3: ncol(databaseB) ]<-as.matrix( datB)
databaseB <- data.frame(databaseB)
colnames(databaseB)=c("x1","x2",paste("R", 1:K, sep = ""),"id")
databaseA <- matrix(0,nA,(p+K+1))
databaseA[,1:2] <- as.matrix(surv_data[idBA,1:2])
databaseA [,3: ncol(databaseA) ]<-as.matrix( datA)
databaseA <- data.frame(databaseA)
colnames(databaseA)=c("Time","delta",paste("R", 1:K, sep = ""),"id")
datA <- databaseA[,-c(1,2)]
datB <-  databaseB[,-c(1,2)]
true_data <- surv_data[idBA,]
return(list(databaseA=databaseA, databaseB = databaseB, prev = prevalence,datA=datA, datB= datB,true_data=true_data))
}
compare_binary <- function(datA, datB, K){
compare1 <- function(k, datA, datB, K){
XA.k = datA[,k]
XB.k = datB[,k]
temp = expand.grid( XB.k,XA.k)
gamma.k = as.numeric(temp[,1]==temp[,2])
return(gamma.k)
}
comp_mat = sapply(1:(K+1), FUN = compare1, datA = datA, datB = datB, K =K)
return(comp_mat)
}
comp_mat.1
nA <- nrow(datA)
nB <-  nrow(datB)
matrice_norm <- t( matrix(g,ncol=nA,nrow=nB))
matrice_norm
vect_sum <- apply(matrice_norm,1, sum)
vect_sum
vect_sum <- apply(matrice_norm,1, sum)
1:length(vect_sum)
##matrice de prob normalisee
Q=matrix(0,nA,nB)
##matrice de prob normalisee
Q=matrix(0,nA,nB)
matrice_norm
vect_sum[
0
]
vect_sum
##matrice de prob normalisee
Q=matrix(0,nA,nB)
Q[i,] <-sapply(1:nA, FUN=function(i){
matrice_norm[i,]/vect_sum[i]
})
matrice_norm[i,]
matrice_norm
i=1
matrice_norm
matrice_norm[i,]
vect_sum[i]
matrice_norm[i,]/vect_sum[i]
matrice_norm[i,]/vect_sum[i]
sapply(1:nA, FUN=function(i){
matrice_norm[i,]/vect_sum[i]
}
sapply(1:nA, FUN=function(i){
matrice_norm[i,]/vect_sum[i]
})
sapply(1:nA, FUN=function(i){
matrice_norm[i,]/vect_sum[i]
})
Q[i,] <-sapply(1:nA, FUN=function(i){
matrice_norm[i,]/vect_sum[i]
})
matrice_norm
Q<-sapply(1:nA, FUN=function(i){
matrice_norm[i,]/vect_sum[i]
})
Q
Q= t(Q)
Q
apply(Q,1, sum)
setwd("C:/Users/fchezeut/Documents")
sport_data = read.csv("Data_évènement_satellite.csv",dec = ",")
sport_data2= lapply(sport_data,as.numeric)
sport_data2= data.frame(lapply(sport_data,as.numeric))
is.numeric(sport_data2$X40m_sprint)
# Rajout de l'IMC ##
class(sport_data2)
sport_data2=data.frame(sport_data2)
sport_data2$IMC <- sport_data2$Weight/(sport_data2$Height/100)^2
#############################
# Visualisation des donnÃ©es #
#############################
#sport_data[sport_data==""]=NA
# Cartographie sur donnÃ©es non standardisÃ©es
z <- as.matrix(t(sport_data2[,-c(1:4,6)]))
rownames(z) <- c("Age","Height","Weight","Sports_per_week","40m_sprint","Free_throw","Wheelchair_race","Golf_strike_length","Bench_press_reps","Climbing_max_left","Climbing_max_right","Climbing_critical_strength","Average_heart_rate","IMC")
z=as.matrix(z[-c(9,12),-c(11,25,26,27,29,31,36:39)])
par(oma=c(0,5,0,0),bg="white")
n <- nrow(z)
p <- ncol(z)
x <- seq(1,p,length.out=p)
y <- seq(1,n,length.out=n)
image(x,y,z,xlab="Variables",ylab="",main="Représentation des données Data Sport (non standardisées)",axes=FALSE)
z=data.frame(z[-c(9,12),-c(11,25,26,27,29,31,36:39)])
View(z)
par(oma=c(0,5,0,0),bg="white")
n <- nrow(z)
p <- ncol(z)
x <- seq(1,p,length.out=p)
y <- seq(1,n,length.out=n)
image(x,y,z,xlab="Variables",ylab="",main="Représentation des données Data Sport (non standardisées)",axes=FALSE)
z= lapply(sport_data,as.numeric)
par(oma=c(0,5,0,0),bg="white")
n <- nrow(z)
p <- ncol(z)
x <- seq(1,p,length.out=p)
y <- seq(1,n,length.out=n)
############### SCENARIOS
nB_sample = c(50,70,100)
nA_sample = round((50*nB_sample)/100)
p = 2
nsim =10
beta = c(0.5,-0.5)
K= 20
error=0.02
prevalence = rep(c(0.05,0.1,0.2,0.3,0.4), K/5)
#lambda0 = rep(0.5,n)
#beta0 = c(0.1,0.1)
#beta = c(0.5,-0.5)
############## Table of scenarios
scenarios = NULL
for (i in 1:length(nA_sample)){
nA = nA_sample[i]
nB= nB_sample[i]
scenarios = rbind(scenarios,c(nsim,nB,nA))
}
colnames(scenarios) = c("nsim","nB","nA")
scenarios=data.frame(scenarios)
##################### matrix
library(survival)
library(rootSolve)
library(nleqslv)
setwd("C:/Users/fchezeut/Documents/GitHub/Cox_matched_data/code_Q_inconnu")
source("2_0_data_generate.R")
source("2_1_record_linkage.R")
source("Record_linkage.R")
source("2_risk_function.R")
source("3_naive_method.R")
source("6_method_EM.R")
source("7_scenarios.R")
#data generation
mf = Generate_data(K,nA,nB,prevalence, min_prev = 0.01)
surv_data = mf$surv_data
XB = mf$XB
data_true=surv_data
idBA=mf$idBA
databaseA=mf$databaseA
databaseB =mf$ databaseB
datA=mf$datA # matching variables
datB= mf$datB
#
linked= linkage_data (databaseB, databaseA) #method theorique
pp=linked$pp
linked= linkage_data (databaseB, databaseA) #method theorique
pp=linked$pp
Q=linked$Q
naive_id_1=linked$naive_id
View(Q)
#####naive
Ndata = generate_naive_data(naive_id_1,XB , surv_data)
naive_data = Ndata$data_naive
Z = as.matrix(naive_data[,-c(1,2)])
Ts = data_true$Time
event = data_true$delta
lambda0 =  rep(0.1,length(event))
lambda0 [which(event == 0)] = 0
beta0 = rep(0.1,p)
# Theoretical estimating equation for true and naive data
fit_true = coxph(Surv(Time,delta)~.,data = data_true)
as.vector(fit_true$coefficients)
# naive method
fit_naive = coxph_equa_naive(Ts,event, Z, maxiter = 20)
fit_naive$coef
# EM method
fit_estimate = Func_itteration(beta0,lambda0,Ts,event,XB,Q,tol= 1e-6,maxits = 600)
fit_estimate$it
fit_estimate$beta0
comp_mat = compare_binary (datA, datB, K)
linked = EM_binary( comp_mat,datA, datB, K, e = 0.02,tol = 1e-5, maxits = 800)
Q=linked$Q
it = linked$it
converge = linked$converge
comp_mat.1 = linked$comp_mat.1
naive_id = linked$naive_id
#####naive
Ndata = generate_naive_data(naive_id,XB , surv_data)
naive_data = Ndata$data_naive
Z = as.matrix(naive_data[,-c(1,2)])
Ts = data_true$Time
event = data_true$delta
lambda0 =  rep(0.1,length(event))
lambda0 [which(event == 0)] = 0
beta0 = rep(0.1,p)
# Theoretical estimating equation for true and naive data
fit_true = coxph(Surv(Time,delta)~.,data = data_true)
coef_true_s[i,] = as.vector(fit_true$coefficients)
# naive method
fit_naive = coxph_equa_naive(Ts,event, Z, maxiter = 20)
fit_naive$coef
# EM method
fit_estimate = Func_itteration(beta0,lambda0,Ts,event,XB,Q,tol= 1e-6,maxits = 600)
fit_estimate$it
fit_estimate$beta0
#record linkage
comp_mat = compare_binary (datA, datB, K)
linked = EM_binary( comp_mat,datA, datB, K, e = 0.02,tol = 1e-5, maxits = 800)
Q=linked$Q
it = linked$it
converge = linked$converge
comp_mat.1 = linked$comp_mat.1
naive_id = linked$naive_id
#####naive
Ndata = generate_naive_data(naive_id,XB , surv_data)
naive_data = Ndata$data_naive
Z = as.matrix(naive_data[,-c(1,2)])
Ts = data_true$Time
event = data_true$delta
lambda0 =  rep(0.1,length(event))
lambda0 [which(event == 0)] = 0
beta0 = rep(0.1,p)
# naive method
fit_naive = coxph_equa_naive(Ts,event, Z, maxiter = 20)
fit_naive$coef
# EM method
fit_estimate = Func_itteration(beta0,lambda0,Ts,event,XB,Q,tol= 1e-6,maxits = 600)
fit_estimate$beta0
fit_estimate$it
View(Q)
#record linkage
comp_mat = compare_binary (datA, datB, K)
linked = EM_binary( comp_mat,datA, datB, K, e = 0.02,tol = 1e-5, maxits = 800)
Q=linked$Q
it = linked$it
View(scenarios)
View(Q)
converge = linked$converge
comp_mat.1 = linked$comp_mat.1
naive_id = linked$naive_id
#####naive
Ndata = generate_naive_data(naive_id,XB , surv_data)
naive_data = Ndata$data_naive
Z = as.matrix(naive_data[,-c(1,2)])
Ts = data_true$Time
event = data_true$delta
lambda0 =  rep(0.1,length(event))
lambda0 [which(event == 0)] = 0
beta0 = rep(0.1,p)
# Theoretical estimating equation for true and naive data
fit_true = coxph(Surv(Time,delta)~.,data = data_true)
# naive method
fit_naive = coxph_equa_naive(Ts,event, Z, maxiter = 20)
fit_naive$coef
# EM method
fit_estimate = Func_itteration(beta0,lambda0,Ts,event,XB,Q,tol= 1e-6,maxits = 600)
fit_estimate$beta0
setwd("C:/Users/fchezeut/Documents/GitHub/Cox_matched_data/code_Q_connu")
source("2_risk_function.R")
################### cumulative function
Funct_lambda2<-function(lambda0,Ts){
#lambda0<- rep(0.1,length(event))
n = length(Ts)
lambda2 = vector()
for (i in 1:n) {
lambda2[i] =  sum(lambda0[which(Ts<=Ts[i])] )
}
return(lambda2=lambda2)
}
########
### proba aposteriories (pi)
Functio_prob<-function(beta0,lambda2,Ts,event,XB, Q){
p=ncol(XB)
X = as.matrix(XB, ncol = p) # covariates
eXbeta0 = exp(X%*% beta0)
n = length(Ts)
m = nrow(XB)
#pi(ij)
prob = matrix(0,n,m)
for (i in 1:n) {
numerateur = vector()
for (j in 1:m) {
numerateur[j] = Q[i,j] * ( eXbeta0[j])^event[i] * exp(-lambda2[i]* eXbeta0[j] )
}
denominateur = sum(numerateur)
prob[i,] = numerateur/denominateur
}
prob
return( prob = prob)
}
#############
################ estimations ###################################
#lambda0 ( baseline hazard function)
Function_lambda0<-function(prob,beta0,Ts,event,XB){
p = ncol(XB)
n = length(Ts)
X = as.matrix(XB, ncol = p) # covariates
eXbeta0 = exp(X%*% beta0)
som1 = prob%*%eXbeta0 # sum with j
lambda0_1 = vector()
for (i in 1:n) {
if(event[i] == 0){lambda0_1[i] = 0
}else if(event[i] != 0 ){
risq = GetRiskSet (Ts[i], Ts)
nrisk = length(risq)
if(nrisk==1){
t2R = som1[risq]  # denominator
}else if(nrisk!=1){
t2R = sum( som1[risq] )
}
lambda0_1[i] = (1/t2R)
}
}
lambda0_1
return( lambda0_1 = lambda0_1)
}
######################
#  estimating equation ########################
equa_estimate <- function(beta,prob,Ts,event,XB) {
p = ncol(XB)
n = length(Ts)
X = as.matrix(XB, ncol = p) # covariates
eXbeta = exp(X%*% beta)
XeXbeta = X*matrix(rep(exp(X%*% beta),p), ncol = p)
#######les sommes pour Z
Z = prob%*%X
#### values for q*exp(beta x) pour tilfe_f
som1 = prob%*%eXbeta
###  values for q*x*exp(beta x)
som2 = prob%*%XeXbeta
## Estimating equation
s = 0
for (i in 1:n) {
risk = GetRiskSet(Ts[i], Ts)
nrisk = length(risk)
if(nrisk==1){
t2R = som1[risk]
t3R = som2[risk,]
}else if(nrisk!=1){
t2R = sum( som1[risk] )
t3R = colSums(som2[risk,] ) }
s= s+ event[i]*(Z[i,] - t3R/t2R)
}
s
return(s=s)
}
#####################
# ###########solve the equation
coxph_estimate<- function(prob,Ts,event,XB,beta_ini,maxiter = 20){
f <- function(x){
equa_estimate  (beta= x,prob,Ts,event,XB)
}
# fit_manual <- nleqslv( c(beta_ini[1],beta_ini[2]),f, method = c("Broyden", "Newton"))
# beta0 <- fit_manual$x
#iterations <- fit_manual$iter
# converge <- as.numeric(( iterations< maxiter)& (fit_manual$scalex==1) )
#xstart <- matrix(rnorm(20,0,1), ncol = 2)
#Zero <-  searchZeros(xstart,f)
fit_manual = multiroot(f,start = beta_ini, maxiter = maxiter)
beta0 = fit_manual$root
iterations =  fit_manual$iter
converge = as.numeric((fit_manual$iter < maxiter)& !is.nan(fit_manual$estim.precis) & !is.na(fit_manual$estim.precis) & (fit_manual$estim.precis<1e-6))
if (iterations  == maxiter) {
cat("WARNING! NOT CONVERGENT FOR NEWTON!", "\n")
converge = FALSE
}
return(list( beta0 = beta0, converge = converge, iterations = iterations) )
}
################
### iterrations ###########################################
#valeurs initials
Func_itteration<-function(beta0,lambda0,Ts,event,XB, Q,tol= 1e-6, maxits = 100){
p = ncol(XB)
n = length(Ts)
beta_ini = rep(0, p)
it = 0
converge = FALSE
while ((!converge) & (it < maxits)){
lambda0.old = lambda0
beta0.old = beta0
#expectation
lambda2 = Funct_lambda2(lambda0.old,Ts)
prob = Functio_prob(beta0.old,lambda2,Ts,event,XB, Q)
#maximization
lambda0 = Function_lambda0 (prob,beta0.old,Ts,event,XB)
estime = coxph_estimate (prob,Ts,event,XB,beta_ini, maxiter = 20)
beta0 = estime$beta0
beta_ini = beta0.old
converge = sqrt (sum ((beta0.old -beta0))^2 + sum ( (lambda0.old - lambda0)^2 ) ) < tol
if (it == maxits) {
cat("WARNING! NOT CONVERGENT WITH EM!", "\n")
converge = FALSE
}else if(is.na(beta0[1]) | is.na(beta0[2])| is.na(beta0[3])| is.na(beta0[4])){
cat("WARNING! beta0 NOT AVAILABLE!", "\n")
converge = FALSE
}
it = it + 1
}
return(list(beta0=beta0, lambda0=lambda0, prob=prob, converge= converge))
}
# EM method
fit_estimate = Func_itteration(beta0,lambda0,Ts,event,XB,Q,tol= 1e-6,maxits = 600)
fit_estimate$it
library(survival)
library(rootSolve)
library(nleqslv)
setwd("C:/Users/fchezeut/Documents/GitHub/Cox_matched_data/code_Q_inconnu")
source("2_0_data_generate.R")
source("2_1_record_linkage.R")
source("Record_linkage.R")
source("2_risk_function.R")
source("3_naive_method.R")
source("6_method_EM.R")
source("7_scenarios.R")
library(survival)
library(rootSolve)
library(nleqslv)
setwd("C:/Users/fchezeut/Documents/GitHub/Cox_matched_data/code_Q_inconnu")
source("2_0_data_generate.R")
source("2_1_record_linkage.R")
source("Record_linkage.R")
source("2_risk_function.R")
source("3_naive_method.R")
source("6_method_EM.R")
source("7_scenarios.R")
#data generation
mf = Generate_data(K,nA,nB,prevalence, min_prev = 0.01)
library(survival)
library(rootSolve)
library(nleqslv)
setwd("C:/Users/fchezeut/Documents/GitHub/Cox_matched_data/code_Q_inconnu")
source("2_0_data_generate.R")
source("2_1_record_linkage.R")
source("Record_linkage.R")
source("2_risk_function.R")
source("3_naive_method.R")
source("6_method_EM.R")
source("7_scenarios.R")
############### SCENARIOS
nB_sample = c(50,70,100)
nA_sample = round((50*nB_sample)/100)
p = 2
nsim =10
beta = c(0.5,-0.5)
K= 25
error=0.02
prevalence = rep(c(0.05,0.1,0.2,0.3,0.4), K/5)
#lambda0 = rep(0.5,n)
#beta0 = c(0.1,0.1)
#beta = c(0.5,-0.5)
############## Table of scenarios
scenarios = NULL
for (i in 1:length(nA_sample)){
nA = nA_sample[i]
nB= nB_sample[i]
scenarios = rbind(scenarios,c(nsim,nB,nA))
}
colnames(scenarios) = c("nsim","nB","nA")
scenarios=data.frame(scenarios)
##################### matrix
library(survival)
library(rootSolve)
library(nleqslv)
setwd("C:/Users/fchezeut/Documents/GitHub/Cox_matched_data/code_Q_inconnu")
source("2_0_data_generate.R")
source("2_1_record_linkage.R")
source("Record_linkage.R")
source("2_risk_function.R")
source("3_naive_method.R")
source("6_method_EM.R")
source("7_scenarios.R")
library(survival)
library(rootSolve)
library(nleqslv)
setwd("C:/Users/fchezeut/Documents/GitHub/Cox_matched_data/code_Q_inconnu")
source("2_0_data_generate.R")
source("2_1_record_linkage.R")
source("Record_linkage.R")
source("2_risk_function.R")
source("3_naive_method.R")
source("6_method_EM.R")
source("7_scenarios.R")
library(survival)
library(rootSolve)
library(nleqslv)
setwd("C:/Users/fchezeut/Documents/GitHub/Cox_matched_data/code_Q_inconnu")
source("2_0_data_generate.R")
source("2_1_record_linkage.R")
source("Record_linkage.R")
source("2_risk_function.R")
source("3_naive_method.R")
source("6_method_EM.R")
source("7_scenarios.R")
