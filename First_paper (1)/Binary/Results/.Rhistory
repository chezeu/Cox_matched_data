u21 = check1(u21,N)
u20 = 1-u22-u21 #check 0,1
if (length(which(u20 < 1/N)) > 0){
u22[which(u20 < 1/N)] = u22[which(u20 < 1/N)] - 1/(2*N)
u21[which(u20 < 1/N)] = u21[which(u20 < 1/N)] - 1/(2*N)
u20[which(u20 < 1/N)] = u20[which(u20 < 1/N)] + 1/N
}
return(list(m22 = m22,m21 = m21,m20=m20,u22=u22,u21=u21,u20=u20))
}
EM3 <- function(comp_mat, datA, datB, K, tol = 1e-6, maxits = 500){
# Starting point
#start <- find_start(comp_mat, datA, datB, K)
start <- start_3(datA, datB, K)
p = start[1]
m22 = start[2:(K+1)]
m21 = start[(K+2):(2*K+1)]
m20 = start[(2*K+2):(3*K+1)]
u22 = start[(3*K+2):(4*K+1)]
u21 = start[(4*K+2):(5*K+1)]
u20 = start[(5*K+2):(6*K+1)]
# initializations
comp_mat  <- comp_mat[,1:K]
N <- nrow(comp_mat)
c20 <- as.numeric(comp_mat==0)
c21 <- as.numeric(comp_mat==1)
c22 <- as.numeric(comp_mat==2)
loglikelihood <- function(p,N,m22, m21, m20, u22,u21, u20, c22, c21, c20){
p2 = E3(m22, m21, m20, u22,u21, u20, N, c22, c21, c20)
pM = p2[,1]
pU = p2[,2]
ll = sum(log(p*pM+(1-p)*pU)) #likelihood not complete likelihood
return(ll)
}
iter <- 0
converge = FALSE
diff <- tol + 1
old.ll = loglikelihood(p,N,m22, m21, m20, u22,u21, u20, c22, c21, c20)
ll = old.ll
while (!converge && iter < maxits){
p.old = p
m22.old = m22 #length K2
m21.old = m21 #length K2
m20.old = m20
u22.old = u22 #length K2
u21.old = u21 #length K2
u20.old = u20
m.old = c(m20.old,m21.old,m22.old)
u.old = c(u20.old,u21.old,u22.old)
############################ E step
p2 = E3(m22, m21, m20, u22,u21, u20, N, c22, c21, c20)
pM = p2[,1]
pU = p2[,2]
# Expectations
g = p*pM/(p*pM+(1-p)*pU)
############################### M step
p = sum(g)/N
max2 = M3(g,K,c22,c21,c20)
m22 = max2$m22
m21 = max2$m21
m20 = max2$m20
u22 = max2$u22
u21 = max2$u21
u20 = max2$u20
m = c(m20,m21,m22)
u = c(u20,u21,u22)
### Stopping
converge <- (abs(p.old - p)/p.old < tol) &&
all(abs(m.old - m)/m.old < tol) &&
all(abs(u.old - u)/u.old < tol)
new.ll = loglikelihood(p,N,m22, m21, m20, u22,u21, u20, c22, c21, c20)
diff <- new.ll - old.ll
old.ll <- new.ll
ll <- c(ll, old.ll)
iter = iter + 1
if (iter == maxits) {
cat("WARNING! NOT CONVERGENT!", "\n")
converge = FALSE
}
}
return(list(g=g, loglikelihood = ll, iter = iter, converge = converge))
}
EM4 <- function(comp_mat, datA, datB, K, tol = 1e-6, maxits = 300){
# Starting point
#start <- find_start(comp_mat, datA, datB, K)
start <- start_4(datA, datB, K)
p = start[1]
m23 = start[2:(K+1)]
m22 = start[(K+2):(2*K+1)]
m21 = start[(2*K+2):(3*K+1)]
m20 = start[(3*K+2):(4*K+1)]
u23 = start[(4*K+2):(5*K+1)]
u22 = start[(5*K+2):(6*K+1)]
u21 = start[(6*K+2):(7*K+1)]
u20 = start[(7*K+2):(8*K+1)]
# initializations
comp_mat  <- comp_mat[,1:K]
N <- nrow(comp_mat)
c20 <- as.numeric(comp_mat==0)
c21 <- as.numeric(comp_mat==1)
c22 <- as.numeric(comp_mat==2)
c23 <- as.numeric(comp_mat==3)
loglikelihood <- function(p,N,m23,m22, m21, m20,u23, u22,u21, u20, c23, c22, c21, c20){
p2 = E4(m23, m22, m21, m20, u23, u22,u21, u20, N, c23, c22, c21, c20)
pM = p2[,1]
pU = p2[,2]
ll = sum(log(p*pM+(1-p)*pU)) #likelihood not complete likelihood
return(ll)
}
iter <- 0
converge = FALSE
diff <- tol + 1
old.ll = loglikelihood(p,N,m23,m22, m21, m20, u23, u22,u21, u20, c23, c22, c21, c20)
ll = old.ll
while (!converge && iter < maxits){
p.old = p
m23.old = m23
m22.old = m22 #length K2
m21.old = m21 #length K2
m20.old = m20
u23.old = u23
u22.old = u22 #length K2
u21.old = u21 #length K2
u20.old = u20
m.old = c(m20.old,m21.old,m22.old, m23.old )
u.old = c(u20.old,u21.old,u22.old, u23.old)
############################ E step
p2 = E4(m23,m22, m21, m20, u23, u22,u21, u20, N, c23, c22, c21, c20)
pM = p2[,1]
pU = p2[,2]
# Expectations
g = p*pM/(p*pM+(1-p)*pU)
############################### M step
p = sum(g)/N
max2 = M4(g,K,c23,c22,c21,c20)
m23 = max2$m23
m22 = max2$m22
m21 = max2$m21
m20 = max2$m20
u23 = max2$u23
u22 = max2$u22
u21 = max2$u21
u20 = max2$u20
m = c(m20,m21,m22, m23)
u = c(u20,u21,u22, u23)
### Stopping
converge <- (abs(p.old - p)/p.old < tol) &&
all(abs(m.old - m)/m.old < tol) &&
all(abs(u.old - u)/u.old < tol)
new.ll = loglikelihood(p,N,m23,m22, m21, m20, u23, u22,u21, u20, c23, c22, c21, c20)
diff <- new.ll - old.ll
old.ll <- new.ll
ll <- c(ll, old.ll)
iter = iter + 1
if (iter == maxits) {
cat("WARNING! NOT CONVERGENT!", "\n")
converge = FALSE
}
}
return(list(g=g, loglikelihood = ll, iter = iter, converge=converge))
}
FS <- function(datA, datB, K,tol=1e-6, maxits = 500){
nA = nrow(datA)
nB =  nrow(datB)
comp_mat <- compare_binary(datA, datB, K)
fit <- EM_binary(comp_mat, datA, datB, K,tol = tol, maxits = maxits)
g = fit$g
converge = fit$converge
# Gmat = matrix(g, nrow = nB, byrow = TRUE)
# Gmat[Gmat<0.5] = 0
# opti_cate <- solve_LSAP(Gmat, maximum = TRUE)
# predict_cate = cbind(seq_along(opti_cate), opti_cate)
# temp = (predict_cate[,1]-1)*nA+ predict_cate[,2]
# # Percentage of correct link
# nPredict = sum((g[temp]>=0.5))
# nTruePredict = sum((predict_cate[,2] == datB[,K+1])&(g[temp]>=0.5))
#
# TPR_FS11= nTruePredict/nB
# PPV_FS11 = nTruePredict/nPredict
threshold = 0.5
index = which(g>= threshold)
TPR_FS5 = sum(comp_mat[index,K+1])/nB
if (length(index)==0){
PPV_FS5 = 1
}else{
PPV_FS5 = sum(comp_mat[index,K+1])/length(index)
}
return(c(TPR_FS5, PPV_FS5, converge))
}
FS3 <- function(datA, datB, K, tol=1e-6, maxits = 500){
nA = nrow(datA)
nB = nrow(datB)
comp_mat <- compare3(datA, datB, K=K)
## Using EM with the above estimated starting point
fit = EM3(comp_mat, datA, datB, K, tol=tol, maxits = maxits)
g = fit$g
converge = fit$converge
# Gmat = matrix(g, nrow = nB, byrow = TRUE)
# Gmat[Gmat<0.5] = 0
# opti_cate <- solve_LSAP(Gmat, maximum = TRUE)
# predict_cate = cbind(seq_along(opti_cate), opti_cate)
# temp = (predict_cate[,1]-1)*nA+ predict_cate[,2]
# # Percentage of correct link
# nPredict = sum((g[temp]>=0.5))
# nTruePredict = sum((predict_cate[,2] == datB[,K+1])&(g[temp]>=0.5))
#
# TPR_FS11= nTruePredict/nB
# PPV_FS11 = nTruePredict/nPredict
threshold = 0.5
index = which(g>= threshold)
TPR_FS5 = sum(comp_mat[index,K+1])/nB
if (length(index)==0){
PPV_FS5 = 1
}else{
PPV_FS5 = sum(comp_mat[index,K+1])/length(index)
}
return(c(TPR_FS5, PPV_FS5, converge))
}
bayesian <- function(datA, datB, K){
nB = nrow(datB)
nA = nrow(datA)
bayes = recordLink(datB[,1:K], datA[,1:K], eps_plus =0.01, eps_minus = 0.01,use_diff = FALSE)
g = as.vector(t(bayes))
# Gmat = bayes
# Gmat[Gmat<0.5] = 0
# opti_cate <- solve_LSAP(Gmat, maximum = TRUE)
# predict_cate = cbind(seq_along(opti_cate), opti_cate)
# temp = (predict_cate[,1]-1)*nA+ predict_cate[,2]
# # Percentage of correct link
# nPredict = sum((g[temp]>=0.5))
# nTruePredict = sum((predict_cate[,2] == datB[,K+1])&(g[temp]>=0.5))
#
# TPR_bayes11= nTruePredict/nB
# PPV_bayes11 = nTruePredict/nPredict
#############################
threshold = 0.5
upper = which(bayes >= threshold)
indexB = upper%%nB
indexB[which(indexB==0)] = nB
indexA = ceiling(upper/nB)
idB = datB[indexB, K+1]
idA = datA[indexA, K+1]
TPR_bayes5 = sum(idA==idB)/nB
if (length(idB) == 0){
PPV_bayes5 = 1
}else{
PPV_bayes5 = sum(idA==idB)/length(idB)
}
return(c(TPR_bayes5, PPV_bayes5, 1))
}
prev = c(0.05,0.1,0.2,0.3,0.4)
doOne1 <- function(nA, nB, K, prev, error){
library(tictoc)
prevalence = rep(prev,  K/5)
data = generate_data(nA = nA, nB = nB, K = K, prevalence = prevalence, error = error)
datA = data$dataA
datB = data$dataB
tic()
FS <- FS(datA, datB, K,  tol=1e-6, maxits = 500)
temp = toc(quiet = TRUE)
time_FS <- temp$toc-temp$tic
tic()
FS3 <- FS3(datA, datB, K,  tol=1e-6, maxits = 500)
temp = toc(quiet = TRUE)
time_FS3 <- temp$toc-temp$tic
#tic()
#FS4 <- FS4(datA, datB, K,  tol=1e-6, maxits = 500)
#temp = toc(quiet = TRUE)
#time_FS4 <- temp$toc-temp$tic
tic()
Bayesian <- bayesian(datA, datB, K)
temp = toc(quiet = TRUE)
time_Bayesian <- temp$toc-temp$tic
results <- c(FS, FS3,FS4, Bayesian, time_FS, time_FS3, time_FS4, time_Bayesian)
return(results)
}
vlis1 <- function(nsim=100) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="frozen", value = 500 ),
nB = list(type="frozen", value = 200),
K = list(type="grid", value = c(30,40,50)),
error = list(type="grid", value = c(0.02,0.04,0.06)),
prev = list(type="frozen", value = 0.2)
)
return(vList)
}
vlis2 <- function(nsim=100) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="frozen", value = 500 ),
nB = list(type="frozen", value = 200),
K = list(type="frozen", value = 40),
error = list(type="frozen", value = 0.04),
prev = list(type="grid", value = c(0.1,0.2,0.3))
)
return(vList)
}
vlis3 <- function(nsim=100) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="grid", value = c(400,800,1200) ),
nB = list(type="frozen", value = 200),
K = list(type="frozen", value = 40),
error = list(type="frozen", value = 0.04),
prev = list(type="frozen", value = 0.2)
)
return(vList)
}
#####################################
runSims <- function(vList=vlis1(),doOne = doOne1, seedList=NULL){
res <- simsalapar::doForeach(vList,  doOne = doOne,  cluster=makeCluster(8, type="PSOCK"), seed = seedList)
return(res)
}
nsim = 100
res1 <- runSims(vlis1(nsim), doOne = doOne1, seedList = 1:nsim)
doOne1 <- function(nA, nB, K, prev, error){
library(tictoc)
prevalence = rep(prev,  K/5)
data = generate_data(nA = nA, nB = nB, K = K, prevalence = prevalence, error = error)
datA = data$dataA
datB = data$dataB
tic()
FS <- FS(datA, datB, K,  tol=1e-6, maxits = 500)
temp = toc(quiet = TRUE)
time_FS <- temp$toc-temp$tic
tic()
FS3 <- FS3(datA, datB, K,  tol=1e-6, maxits = 500)
temp = toc(quiet = TRUE)
time_FS3 <- temp$toc-temp$tic
#tic()
#FS4 <- FS4(datA, datB, K,  tol=1e-6, maxits = 500)
#temp = toc(quiet = TRUE)
#time_FS4 <- temp$toc-temp$tic
tic()
Bayesian <- bayesian(datA, datB, K)
temp = toc(quiet = TRUE)
time_Bayesian <- temp$toc-temp$tic
results <- c(FS, FS3, Bayesian, time_FS, time_FS3,  time_Bayesian)
return(results)
}
vlis1 <- function(nsim=100) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="frozen", value = 500 ),
nB = list(type="frozen", value = 200),
K = list(type="grid", value = c(30,40,50)),
error = list(type="grid", value = c(0.02,0.04,0.06)),
prev = list(type="frozen", value = 0.2)
)
return(vList)
}
vlis2 <- function(nsim=100) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="frozen", value = 500 ),
nB = list(type="frozen", value = 200),
K = list(type="frozen", value = 40),
error = list(type="frozen", value = 0.04),
prev = list(type="grid", value = c(0.1,0.2,0.3))
)
return(vList)
}
vlis3 <- function(nsim=100) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="grid", value = c(400,800,1200) ),
nB = list(type="frozen", value = 200),
K = list(type="frozen", value = 40),
error = list(type="frozen", value = 0.04),
prev = list(type="frozen", value = 0.2)
)
return(vList)
}
#####################################
runSims <- function(vList=vlis1(),doOne = doOne1, seedList=NULL){
res <- simsalapar::doForeach(vList,  doOne = doOne,  cluster=makeCluster(8, type="PSOCK"), seed = seedList)
return(res)
}
nsim = 10
vlis3 <- function(nsim=10) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="grid", value = c(400,800,1200) ),
nB = list(type="frozen", value = 200),
K = list(type="frozen", value = 40),
error = list(type="frozen", value = 0.04),
prev = list(type="frozen", value = 0.2)
)
return(vList)
}
vlis2 <- function(nsim=10) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="frozen", value = 500 ),
nB = list(type="frozen", value = 200),
K = list(type="frozen", value = 40),
error = list(type="frozen", value = 0.04),
prev = list(type="grid", value = c(0.1,0.2,0.3))
)
return(vList)
}
vlis1 <- function(nsim=10) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="frozen", value = 500 ),
nB = list(type="frozen", value = 200),
K = list(type="grid", value = c(30,40,50)),
error = list(type="grid", value = c(0.02,0.04,0.06)),
prev = list(type="frozen", value = 0.2)
)
return(vList)
}
#####################################
runSims <- function(vList=vlis1(),doOne = doOne1, seedList=NULL){
res <- simsalapar::doForeach(vList,  doOne = doOne,  cluster=makeCluster(8, type="PSOCK"), seed = seedList)
return(res)
}
nsim = 10
res1 <- runSims(vlis1(nsim), doOne = doOne1, seedList = 1:nsim)
View(res1)
res1[[1]]
save(res1, file="0722_100s_res1_binary.RData")
View(res1)
res1[[1]]
# Make error for one binary vector x
makeError <- function(x,error){
#x is a column of B
#error is a proportion of error
nE  = round(length(x)*error)
index = sample(1:length(x), nE)
x[index] = 1-x[index]
return(x)
}
generate_data <- function(nA, nB, K, prevalence, error, min_prev = 0.01){
#prevalence = rep(c(0.05,0.1,0.2,0.3,0.4), K/5)
# First database A
datA = matrix(0, nrow = nA, ncol = K+1)
datA[,K+1] = 1:nA #id
conditionA = TRUE
while (conditionA){
datA[,1:K] = sapply(prevalence, function(x){rbinom(n=nA, size = 1,prob = x)})
conditionA = (sum(colSums(datA[,1:K]/nA) >= min_prev) < K)
}
datA = data.frame(datA)
colnames(datA)=c(paste("R", 1:K, sep = ""),"id")
conditionB = TRUE
while (conditionB) {
# Second database B
idAB <- sample(1:nA,nB) #ident in A appearing in B
datB <- datA[idAB,]
# Make error for B
datB[,1:K]= apply(datB[,1:K], MARGIN = 2, FUN = makeError, error = error)
conditionB = (sum(colSums(datB[,1:K]) >= 1) < K)
}
return(list(dataA=datA, dataB = datB, prev = prevalence))
}
nA=40
nB=20
K=10
error=30/100
prevalence = rep(c(0.05,0.1,0.2,0.3,0.4), K/5)
gen <- generate_data (nA, nB, K, prevalence, error, min_prev = 0.01)
datA <- gen$dataA
datB <- gen$dataB
prev <- gen$prev
vlis1 <- function(nsim=5) {
vList <- simsalapar::varlist(
n.sim = list(value = nsim, expr = quote(N[sim])), # , type = "N"
nA = list(type="frozen", value = 500 ),
nB = list(type="frozen", value = 200),
K = list(type="grid", value = c(30,40,50)),
error = list(type="grid", value = c(0.02,0.04,0.06)),
prev = list(type="frozen", value = 0.2)
)
return(vList)
}
#####################################
runSims <- function(vList=vlis1(),doOne = doOne1, seedList=NULL){
res <- simsalapar::doForeach(vList,  doOne = doOne,  cluster=makeCluster(8, type="PSOCK"), seed = seedList)
return(res)
}
nsim = 5
res1 <- runSims(vlis1(nsim), doOne = doOne1, seedList = 1:nsim)
save(res1, file="0722_100s_res1_binary.RData")
View(res1)
View(res1)
res1[[1]]
res1[[5]]
load("0720_1000s_res1_binary.RData")
val <- getArray(res1)
library(simsalapar)
library(stringr)
library(reshape2)
library(dplyr)
library(tidyr)
library(tidyverse)
library(remotes)
#setwd("C:\\Users\\Admin\\Dropbox\\R_program\\First_paper\\Binary\\Results")
#setwd("C:\\Users\\thanhvo\\Dropbox\\R_program\\First_paper\\Binary\\Results")
setwd("C:\\Users\\thhvo.BCOM\\Dropbox\\R_program\\First_paper\\Binary\\Results")
#setwd("C:\\Users\\Admin\\Dropbox\\R_program\\First_paper\\Binary\\Results")
#setwd("C:\\Users\\thanhvo\\Dropbox\\R_program\\First_paper\\Binary\\Results")
setwd("D:/chezeu article/code-vanessa/First_paper (1)/Binary/Results")
load("0720_1000s_res1_binary.RData")
val <- getArray(res1)
dimnames(val)[[1]]=list("TPR FS","PPV FS", "converge FS",
"TPR FS3","PPV FS3","converge FS3",
"TPR FS4","PPV FS4", "converge FS4",
"TPR Bayes","PPV Bayes","converge Bayes",
"time FS", "time FS3", "time FS4", "time Bayes")
df <- array2df(val)
View(df)
